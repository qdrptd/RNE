{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qdrptd/RNE/blob/main/YTCrawl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIoVy8pWIzKX",
        "outputId": "85e08f83-25d3-4f21-c9df-409032d1233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.5)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.9)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (37.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.5.18.1)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.2.0)\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 3,626 B in 3s (1,182 B/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (101.0.4951.64-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nGSpf29EI4hd"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "import time\n",
        "from openpyxl import Workbook\n",
        "import pandas as pd\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asb1kLaNI7ns",
        "outputId": "5578f225-224e-45e2-bea7-f1442c8d9ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: UTF-8 -*-\n",
        "import time\n",
        "from selenium import webdriver\n",
        "import requests\n",
        "!pip install xlsxwriter\n",
        "#Colab에선 웹브라우저 창이 뜨지 않으므로 별도 설정한다.\n",
        " \n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')        # Head-less 설정\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver.quit()"
      ],
      "metadata": {
        "id": "FmK2TxVJ1wZU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_17qaL4qJIB_",
        "outputId": "738d24b8-e27d-40cc-be75-d802d29110ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:88: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:93: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "종료\n"
          ]
        }
      ],
      "source": [
        "#해당 url로 이동\n",
        "pd_metadata = {}\n",
        "pd_comments = pd.DataFrame({})\n",
        "for t in range(3, 4):\n",
        "  type_n = open('type'+str(t)+\".txt\").readlines()\n",
        "  search_data = {}\n",
        "  for search in type_n:\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    url = \"https://www.youtube.com/results?search_query=\" + search #search 단어를 검색했을 때 나오는 페이지\n",
        "    driver.get(url)\n",
        "    driver.execute_script(\"window.scrollTo(0,1000)\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 페이지 끝까지 스크롤(복사)\n",
        "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "    print(last_height)\n",
        "    while True:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "        time.sleep(1.5)\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "        last_height = new_height\n",
        "\n",
        "        if new_height > 100000: #동영상은 꽤 많이 나와서, 페이지 길이에 한계를 설정\n",
        "          break\n",
        "\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    video_list = soup.select(\"a#video-title\")\n",
        "\n",
        "    id, titles = [], []\n",
        "    for video in video_list: \n",
        "      id.append(video['href']) #동영상 ID(링크) \n",
        "      titles.append(video['title']) #동영상 제목\n",
        "    views, channels, subs = [], [], []\n",
        "    channel_id_list = soup.select('div#channel-info > a')\n",
        "    views_list = soup.select(\"div#metadata > div > span:nth-of-type(1)\")\n",
        "    time_list = soup.select(\"div#metadata > div > span:nth-of-type(2)\")\n",
        "    # for channel_id in channel_id_list:\n",
        "    #   try:\n",
        "    #     channels.append(channel_id['href'])\n",
        "    #     channel_url = \"https://www.youtube.com\" + channel_id['href']\n",
        "    #     channel_html = requests.get(channel_url).text\n",
        "    #     channel_soup = BeautifulSoup(channel_html, 'html.parser')\n",
        "    #     subs.append(channel_soup.find('#subscriber-count'))\n",
        "    #   except:\n",
        "    #     pass\n",
        "      \n",
        "    for v in views_list:\n",
        "      views.append(v.text)\n",
        "    # search_data[search] = {\"아이디\" : id, \"제목\" : titles, \"조회수\": views, \"채널\": channels, \"구독자\": subs}\n",
        "    id_final = []\n",
        "    comment_final = []\n",
        "    video_comments_data = {}\n",
        "    for video_id in id:\n",
        "      url = \"https://www.youtube.com\" + video_id\n",
        "      try:\n",
        "        driver.get(url)\n",
        "      except:\n",
        "        break\n",
        "      driver.implicitly_wait(3)\n",
        "\n",
        "      time.sleep(1.5)\n",
        "\n",
        "      driver.execute_script(\"window.scrollTo(0,1000)\")\n",
        "      time.sleep(3)\n",
        "\n",
        "      # 페이지 끝까지 스크롤\n",
        "      last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "\n",
        "      while True:\n",
        "          driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "          time.sleep(1.5)\n",
        "\n",
        "          new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "          if new_height == last_height:\n",
        "              break\n",
        "          last_height = new_height\n",
        "          if new_height > 100000:\n",
        "            break\n",
        "\n",
        "      time.sleep(1.5)\n",
        "\n",
        "      # 팝업 닫기\n",
        "      try:\n",
        "          driver.find_element_by_css_selector(\"#dismiss-button > a\").click()\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "      # 대댓글 모두 열기\n",
        "      buttons = driver.find_elements_by_css_selector(\"#more-replies > a\")\n",
        "\n",
        "      time.sleep(1.5)\n",
        "\n",
        "      for button in buttons:\n",
        "          button.send_keys(Keys.ENTER)\n",
        "          time.sleep(1.5)\n",
        "          try:\n",
        "            button.click()\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "      time.sleep(1.5)\n",
        "\n",
        "      # 정보 추출하기\n",
        "      html_source = driver.page_source\n",
        "      soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "      id_list = soup.select(\"div#header-author > h3 > #author-text > span\")\n",
        "      comment_list = soup.select(\"yt-formatted-string#content-text\")\n",
        "      for i in range(len(comment_list)):\n",
        "        temp_id = id_list[i].text\n",
        "        temp_id = temp_id.replace('\\n', '')\n",
        "        temp_id = temp_id.replace('\\t', '')\n",
        "        temp_id = temp_id.replace('    ', '')\n",
        "        id_final.append(temp_id)\n",
        "\n",
        "        temp_comment = comment_list[i].text\n",
        "        temp_comment = temp_comment.replace('\\n', '')\n",
        "        temp_comment = temp_comment.replace('\\t', '')\n",
        "        temp_comment = temp_comment.replace('    ', '')\n",
        "        comment_final.append(temp_comment)\n",
        "      pd_comments = pd.concat([pd_comments, pd.DataFrame({'타입': t, '검색어': search,'영상': video_id,'작성자': id_final, '내용': comment_final})])\n",
        "      print(\"종료\")\n",
        "  print()\n",
        "      \n",
        "  # pd_metadata['type' + str(i)] = search_data\n",
        "print(pd_comments)\n",
        "pd.DataFrame(pd_comments).to_excel(\"comments.xlsx\")\n",
        "# pd_metadata = pd.DataFrame(pd_metadata)\n",
        "# pd_metadata.to_excel('metadata.xlsx')\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcjqBdGnJqMG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a4nIR_bklYkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "YTCrawl.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN89l9xjQLsp/P5G9u8/Fl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}